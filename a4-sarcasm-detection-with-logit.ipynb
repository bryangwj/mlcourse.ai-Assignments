{"cells":[{"metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \nAuthor: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."},{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"## <center> Assignment 4. Sarcasm detection with logistic regression\n    \nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />"},{"metadata":{"trusted":true,"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247"},"cell_type":"code","source":"!ls ../input/sarcasm/","execution_count":1,"outputs":[{"output_type":"stream","text":"test-balanced.csv    train-balanced-sarc.csv.gz\r\ntest-unbalanced.csv  train-balanced-sarcasm.csv\r\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4"},"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856"},"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27"},"cell_type":"code","source":"train_df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78"},"cell_type":"code","source":"train_df.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1010826 entries, 0 to 1010825\nData columns (total 10 columns):\nlabel             1010826 non-null int64\ncomment           1010773 non-null object\nauthor            1010826 non-null object\nsubreddit         1010826 non-null object\nscore             1010826 non-null int64\nups               1010826 non-null int64\ndowns             1010826 non-null int64\ndate              1010826 non-null object\ncreated_utc       1010826 non-null object\nparent_comment    1010826 non-null object\ndtypes: int64(4), object(6)\nmemory usage: 77.1+ MB\n","name":"stdout"}]},{"metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"},"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows."},{"metadata":{"trusted":true,"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08"},"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"We notice that the dataset is indeed balanced"},{"metadata":{"trusted":true,"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11"},"cell_type":"code","source":"train_df['label'].value_counts()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0    505405\n1    505368\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"},"cell_type":"markdown","source":"We split data into training and validation parts."},{"metadata":{"trusted":true,"_uuid":"c200add4e1dcbaa75164bbcc73b9c12ecb863c96"},"cell_type":"code","source":"train_texts, valid_texts, y_train, y_valid = \\\n        train_test_split(train_df['comment'], train_df['label'], random_state=17)","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"},"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['subreddit'])['label'].agg(np.size).sort_values(ascending=False).head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"subreddit\nAskReddit          65674\npolitics           39493\nworldnews          26376\nleagueoflegends    21034\npcmasterrace       18987\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom wordcloud import WordCloud, STOPWORDS\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\n## custom function for ngram generation ##\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n## custom function for horizontal bar chart ##\ndef horizontal_bar_chart(df, color):\n    trace = go.Bar(\n        y=df[\"word\"].values[::-1],\n        x=df[\"wordcount\"].values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n## Get the bar chart from sarcastic (label = 1) and non-sarcastic (label = 0) comments ##\nfreq_dict0 = defaultdict(int)\nfreq_dict1 = defaultdict(int)\nfor index, value in y_train.items():\n    if value == 0:\n        for word in generate_ngrams(train_texts[index],3):\n            freq_dict0[word] += 1\n    else:\n        for word in generate_ngrams(train_texts[index],3):\n            freq_dict1[word] += 1\n        \nfd_sorted0 = pd.DataFrame(sorted(freq_dict0.items(), key=lambda x: x[1])[::-1])\nfd_sorted0.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted0.head(50), 'blue')\n\nfd_sorted1 = pd.DataFrame(sorted(freq_dict1.items(), key=lambda x: x[1])[::-1])\nfd_sorted1.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted1.head(50), 'blue')\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n                          subplot_titles=[\"Frequent words of non-sarcastic comments\", \n                                          \"Frequent words of sarcastic comments\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\npy.iplot(fig, filename='word-plots')","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>","text/vnd.plotly.v1+html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"},"metadata":{}},{"output_type":"stream","text":"This is the format of your plot grid:\n[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n\n","name":"stdout"},{"output_type":"display_data","data":{"application/vnd.plotly.v1+json":{"data":[{"marker":{"color":"blue"},"orientation":"h","showlegend":false,"x":[78,83,84,84,107,124,124,125,125,127,130,131,132,133,133,134,139,139,139,140,140,187,188,199,199,200,279,286,383,383,419,419,475,527,527,528,614,618,783,783,899,899,1010,1069,1110,1110,1248,1340,1665,3233],"y":["cuck cuck cuck","fedora fedora fedora","best best best","f5 f5 f5","shots shots shots","united states first","states first lady","first lady united","lady united states","nope nope nope","opieop opieop opieop","sli smp nvidia","edition sli smp","founders edition sli","smp nvidia gtx","nvidia gtx 1080","1070 1060 1050","1060 1050 founders","1050 founders edition","gtx 1080 1070","1080 1070 1060","nothing, got nothing,","got nothing, got","family trump first","trump first family","first family trump","kek kek kek","wat wat wat","tronald dump tronald","dump tronald dump","lm ayy lm","ayy lm ayy","cmd cmd cmd","trumps hate love","hate love trumps","love trumps hate","gjallarhorn gjallarhorn gjallarhorn","ziggo ziggo ziggo","donald trump donald","trump donald trump","fake news fake","news fake news","raving raving raving","liar liar liar","iphone 7 iphone","7 iphone 7","comcast comcast comcast","jerry jerry jerry","money money money","fuck fuck fuck"],"type":"bar","uid":"de0d7946-6d19-468e-b65f-107860d60710","xaxis":"x","yaxis":"y"},{"marker":{"color":"blue"},"orientation":"h","showlegend":false,"x":[24,24,24,25,25,26,26,27,27,27,27,28,28,28,28,29,29,29,29,31,32,34,34,35,36,36,37,37,38,38,38,39,39,42,43,45,46,53,55,56,58,59,61,67,68,69,70,84,98,180],"y":["fuel melt steel","america great again!","never done anything","every single person","yeah im sure","never gets old","jet fuel melt","works mysterious ways.","oh yeah, totally","see 30 fps","heard one before.","makes much sense","blah blah blah","joke never gets","every single one","know talking about.","yeah fuck people","never gets old.","good old days","pc master race","will take care","wow, never seen","im pretty sure","good thing got","goddamn antisemitic bastard!","12 year old","wow never seen","god works mysterious","never seen before.","eye see past","well good thing","racist white people","ha ha ha","yeah, fuck people","never seen one","free market will","possibly go wrong?","makes perfect sense","make america great","please tell forgot","hahahahaha hahahahaha hahahahaha","desu desu desu","never heard one","f5 f5 f5","`svchost.exe` `svchost.exe` `svchost.exe`","oh come on,","here, dropped this:","many, many, many,","think dropped this:","human eye see"],"type":"bar","uid":"faa0b4e0-cc22-4e12-b812-6bb9bcec7962","xaxis":"x2","yaxis":"y2"}],"layout":{"annotations":[{"font":{"size":16},"showarrow":false,"text":"Frequent words of non-sarcastic comments","x":0.225,"xanchor":"center","xref":"paper","y":1,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"Frequent words of sarcastic comments","x":0.775,"xanchor":"center","xref":"paper","y":1,"yanchor":"bottom","yref":"paper"}],"xaxis":{"anchor":"y","domain":[0,0.45]},"yaxis":{"anchor":"x","domain":[0,1]},"xaxis2":{"anchor":"y2","domain":[0.55,1]},"yaxis2":{"anchor":"x2","domain":[0,1]},"height":1200,"width":900,"paper_bgcolor":"rgb(233,233,233)","title":{"text":"Trigram Count Plots"}},"config":{"showLink":false,"linkText":"Export to plot.ly","plotlyServerURL":"https://plot.ly"}},"text/html":"<div id=\"eddc511e-8d45-40e6-b7f2-416e2f9f55b8\" style=\"height: 1200px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"eddc511e-8d45-40e6-b7f2-416e2f9f55b8\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [78, 83, 84, 84, 107, 124, 124, 125, 125, 127, 130, 131, 132, 133, 133, 134, 139, 139, 139, 140, 140, 187, 188, 199, 199, 200, 279, 286, 383, 383, 419, 419, 475, 527, 527, 528, 614, 618, 783, 783, 899, 899, 1010, 1069, 1110, 1110, 1248, 1340, 1665, 3233], \"y\": [\"cuck cuck cuck\", \"fedora fedora fedora\", \"best best best\", \"f5 f5 f5\", \"shots shots shots\", \"united states first\", \"states first lady\", \"first lady united\", \"lady united states\", \"nope nope nope\", \"opieop opieop opieop\", \"sli smp nvidia\", \"edition sli smp\", \"founders edition sli\", \"smp nvidia gtx\", \"nvidia gtx 1080\", \"1070 1060 1050\", \"1060 1050 founders\", \"1050 founders edition\", \"gtx 1080 1070\", \"1080 1070 1060\", \"nothing, got nothing,\", \"got nothing, got\", \"family trump first\", \"trump first family\", \"first family trump\", \"kek kek kek\", \"wat wat wat\", \"tronald dump tronald\", \"dump tronald dump\", \"lm ayy lm\", \"ayy lm ayy\", \"cmd cmd cmd\", \"trumps hate love\", \"hate love trumps\", \"love trumps hate\", \"gjallarhorn gjallarhorn gjallarhorn\", \"ziggo ziggo ziggo\", \"donald trump donald\", \"trump donald trump\", \"fake news fake\", \"news fake news\", \"raving raving raving\", \"liar liar liar\", \"iphone 7 iphone\", \"7 iphone 7\", \"comcast comcast comcast\", \"jerry jerry jerry\", \"money money money\", \"fuck fuck fuck\"], \"type\": \"bar\", \"uid\": \"de0d7946-6d19-468e-b65f-107860d60710\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [24, 24, 24, 25, 25, 26, 26, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 31, 32, 34, 34, 35, 36, 36, 37, 37, 38, 38, 38, 39, 39, 42, 43, 45, 46, 53, 55, 56, 58, 59, 61, 67, 68, 69, 70, 84, 98, 180], \"y\": [\"fuel melt steel\", \"america great again!\", \"never done anything\", \"every single person\", \"yeah im sure\", \"never gets old\", \"jet fuel melt\", \"works mysterious ways.\", \"oh yeah, totally\", \"see 30 fps\", \"heard one before.\", \"makes much sense\", \"blah blah blah\", \"joke never gets\", \"every single one\", \"know talking about.\", \"yeah fuck people\", \"never gets old.\", \"good old days\", \"pc master race\", \"will take care\", \"wow, never seen\", \"im pretty sure\", \"good thing got\", \"goddamn antisemitic bastard!\", \"12 year old\", \"wow never seen\", \"god works mysterious\", \"never seen before.\", \"eye see past\", \"well good thing\", \"racist white people\", \"ha ha ha\", \"yeah, fuck people\", \"never seen one\", \"free market will\", \"possibly go wrong?\", \"makes perfect sense\", \"make america great\", \"please tell forgot\", \"hahahahaha hahahahaha hahahahaha\", \"desu desu desu\", \"never heard one\", \"f5 f5 f5\", \"`svchost.exe` `svchost.exe` `svchost.exe`\", \"oh come on,\", \"here, dropped this:\", \"many, many, many,\", \"think dropped this:\", \"human eye see\"], \"type\": \"bar\", \"uid\": \"faa0b4e0-cc22-4e12-b812-6bb9bcec7962\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of non-sarcastic comments\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sarcastic comments\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 1200, \"width\": 900, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": {\"text\": \"Trigram Count Plots\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>","text/vnd.plotly.v1+html":"<div id=\"eddc511e-8d45-40e6-b7f2-416e2f9f55b8\" style=\"height: 1200px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"eddc511e-8d45-40e6-b7f2-416e2f9f55b8\", [{\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [78, 83, 84, 84, 107, 124, 124, 125, 125, 127, 130, 131, 132, 133, 133, 134, 139, 139, 139, 140, 140, 187, 188, 199, 199, 200, 279, 286, 383, 383, 419, 419, 475, 527, 527, 528, 614, 618, 783, 783, 899, 899, 1010, 1069, 1110, 1110, 1248, 1340, 1665, 3233], \"y\": [\"cuck cuck cuck\", \"fedora fedora fedora\", \"best best best\", \"f5 f5 f5\", \"shots shots shots\", \"united states first\", \"states first lady\", \"first lady united\", \"lady united states\", \"nope nope nope\", \"opieop opieop opieop\", \"sli smp nvidia\", \"edition sli smp\", \"founders edition sli\", \"smp nvidia gtx\", \"nvidia gtx 1080\", \"1070 1060 1050\", \"1060 1050 founders\", \"1050 founders edition\", \"gtx 1080 1070\", \"1080 1070 1060\", \"nothing, got nothing,\", \"got nothing, got\", \"family trump first\", \"trump first family\", \"first family trump\", \"kek kek kek\", \"wat wat wat\", \"tronald dump tronald\", \"dump tronald dump\", \"lm ayy lm\", \"ayy lm ayy\", \"cmd cmd cmd\", \"trumps hate love\", \"hate love trumps\", \"love trumps hate\", \"gjallarhorn gjallarhorn gjallarhorn\", \"ziggo ziggo ziggo\", \"donald trump donald\", \"trump donald trump\", \"fake news fake\", \"news fake news\", \"raving raving raving\", \"liar liar liar\", \"iphone 7 iphone\", \"7 iphone 7\", \"comcast comcast comcast\", \"jerry jerry jerry\", \"money money money\", \"fuck fuck fuck\"], \"type\": \"bar\", \"uid\": \"de0d7946-6d19-468e-b65f-107860d60710\", \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"marker\": {\"color\": \"blue\"}, \"orientation\": \"h\", \"showlegend\": false, \"x\": [24, 24, 24, 25, 25, 26, 26, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 31, 32, 34, 34, 35, 36, 36, 37, 37, 38, 38, 38, 39, 39, 42, 43, 45, 46, 53, 55, 56, 58, 59, 61, 67, 68, 69, 70, 84, 98, 180], \"y\": [\"fuel melt steel\", \"america great again!\", \"never done anything\", \"every single person\", \"yeah im sure\", \"never gets old\", \"jet fuel melt\", \"works mysterious ways.\", \"oh yeah, totally\", \"see 30 fps\", \"heard one before.\", \"makes much sense\", \"blah blah blah\", \"joke never gets\", \"every single one\", \"know talking about.\", \"yeah fuck people\", \"never gets old.\", \"good old days\", \"pc master race\", \"will take care\", \"wow, never seen\", \"im pretty sure\", \"good thing got\", \"goddamn antisemitic bastard!\", \"12 year old\", \"wow never seen\", \"god works mysterious\", \"never seen before.\", \"eye see past\", \"well good thing\", \"racist white people\", \"ha ha ha\", \"yeah, fuck people\", \"never seen one\", \"free market will\", \"possibly go wrong?\", \"makes perfect sense\", \"make america great\", \"please tell forgot\", \"hahahahaha hahahahaha hahahahaha\", \"desu desu desu\", \"never heard one\", \"f5 f5 f5\", \"`svchost.exe` `svchost.exe` `svchost.exe`\", \"oh come on,\", \"here, dropped this:\", \"many, many, many,\", \"think dropped this:\", \"human eye see\"], \"type\": \"bar\", \"uid\": \"faa0b4e0-cc22-4e12-b812-6bb9bcec7962\", \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of non-sarcastic comments\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Frequent words of sarcastic comments\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"height\": 1200, \"width\": 900, \"paper_bgcolor\": \"rgb(233,233,233)\", \"title\": {\"text\": \"Trigram Count Plots\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vec = TfidfVectorizer(ngram_range = (1,3))\n#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n\n#c_values = np.logspace(0, 1, 5)\n\nlogit = LogisticRegression(C=0.5, random_state=17, verbose=1, n_jobs=-1)\n\npipe = Pipeline([('tfidf_vec',tfidf_vec),('logit',logit)])\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npipe.fit(train_texts, y_train)","execution_count":17,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n\nDefault solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning:\n\n'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n\n","name":"stderr"},{"output_type":"stream","text":"[LibLinear]CPU times: user 3min 4s, sys: 4.33 s, total: 3min 8s\nWall time: 3min 8s\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"Pipeline(memory=None,\n     steps=[('tfidf_vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=T...  penalty='l2', random_state=17, solver='warn', tol=0.0001,\n          verbose=1, warm_start=False))])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pipe.predict(valid_texts)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, pred)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"0.7204247033962026"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}